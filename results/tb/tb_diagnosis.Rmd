---
title: "Predicting TB Risk Using a Risk Score Model"
date: "February 2024"
output:
  word_document: default
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
#devtools::install_github("hjeglinton/riskscores", build_vignettes = TRUE)

library(knitr)
library(xtable)
library(glmnet)
library(pROC)
library(tableone)
library(glmnet)
library(caret)
library(gridExtra)
#library(kableExtra)
library(gtsummary)
library(riskscores)
library(probably)


set.seed(1)


```

# Data Preprocessing 



```{r}
# read in raw data 
kharitode <- read.csv("../../data/tb/Kharitodestudy.csv")
stomp <- read.csv("../../data/tb/STOMPstudy.csv")

```



```{r, warning = FALSE}
# run pre-processing steps
setwd("/Users/hannaheglinton/Documents/GitHub/thesis/R")
source('preprocessing.R')

### Derivation Data 
deriv_df <- kharitode_preprocessing(kharitode)

der_matrix <- model.matrix(tb ~ ., data=deriv_df)
der_matrix <- cbind(der_matrix, tb = as.numeric(as.vector(deriv_df$tb)))

X_der <- as.matrix(der_matrix[,-ncol(der_matrix)])
y_der <- der_matrix[,ncol(der_matrix)] %>% as.vector


### Validation Data
val_df <- stomp_preprocessing(stomp)

val_matrix <- model.matrix(tb ~ ., data=val_df)
val_matrix <- cbind(val_matrix, tb = as.numeric(as.vector(val_df$tb)))

X_val <- as.matrix(val_matrix[,-ncol(val_matrix)])
y_val <- val_matrix[,ncol(val_matrix)] %>% as.vector()



# set fold ids
foldids <- stratify_folds(y_der, nfolds = 10, seed = 1)

```

# Rounded Lasso Model Fitting

```{r}
 # Lasso

mod_lasso <- cv.glmnet(X_der[,-1], y_der, foldids = foldids, alpha = 1, family = "binomial") 

coef_lasso <- coef(mod_lasso, lambda = mod_lasso$lambda.min)
coef_lasso

coef_lasso_vec <- as.vector(coef_lasso)

# Rounded Lasso 
scalar <- median(abs(coef_lasso_vec[coef_lasso_vec != 0][-1]))

b0_lasso_scaled <- coef_lasso_vec[1]/scalar
coef_lasso_rounded <- c(b0_lasso_scaled, 
                        round(coef_lasso_vec[-1]/scalar, 0))

data.frame(variable = coef_lasso@Dimnames[[1]], coef = coef_lasso_rounded)

scores <- as.vector(X_der %*% coef_lasso_rounded)
lasso_score_mod <- glm(y_der ~ scores, family = "binomial")


```



# NLLCD Model Fitting 




```{r, out.width="75%", fig.align = 'center', warning = FALSE}

# CV
cv_results <- cv_risk_mod(X_der, y_der, foldids = foldids, a = -6, b = 6, nlambda = 25)

plot(cv_results, lambda_text = FALSE) + 
  labs(title = "Figure 1. Cross Validation Results")



```

```{r, warning = FALSE}
lambda0 <- cv_results$lambda_min

mod <- risk_mod(X_der, y_der, lambda0 = lambda0, a = -6, b = 6)

# get score card
mod$model_card
```

```{r}
# plot score vs risk 


predict_df <- data.frame(score = predict(mod, type = "score"),
                         response = predict(mod, type = "response"))

score_v_risk <- ggplot() + 
  geom_function(data = data.frame(x = seq(0,20)), aes(x), 
                fun = function(x) get_risk(mod, x), size = 1, alpha = 0.9) + 
  labs(x = "RiskCD Score", y = "Risk of TB", title = "") +
  theme_bw() + 
  theme(axis.text = element_text(size = 10), panel.grid.minor.y = element_blank()) + 
  scale_x_continuous(breaks = seq(0, 20, 2)) + 
  scale_y_continuous(breaks = seq(0, 1, 0.1))

#ggsave(score_v_risk, width = 7, height = 5, dpi = 300, filename = "score_v_risk_plot.png")
```


```{r}
# Baik 2020 coefficients 
coef_baik <- data.frame(variable = names(mod$beta),
                        coef = c(0, 0, 1, 1, 0, 2, 1, 0, 0, 1, 0,
                                 1, 1, 2, 3))

baik_scores <- as.vector(X_der %*% coef_baik$coef)
baik_score_mod <- glm(y_der ~ baik_scores, family = "binomial")
  
  
```

```{r}
# Compare coefficients

data.frame(variable = names(mod$beta), 
           lasso = round(coef_lasso_vec,3), 
           rounded_lasso = coef_lasso_rounded,
           baik = coef_baik$coef,
           nllcd = as.vector(mod$beta)) %>%
  slice(-1)
```



# Model Validation 

```{r}
# Get lasso predicted probabilities
lasso_pred_der <- predict(mod_lasso, X_der[,-1], type = "response") %>% as.vector
lasso_pred_val <- predict(mod_lasso, X_val[,-1], type = "response") %>% as.vector

# Get rlasso predicted probabilities 
scores_lasso_val <- data.frame(scores = X_val %*% coef_lasso_rounded)
rlasso_pred_der <- predict(lasso_score_mod, type = "response") %>% as.vector
rlasso_pred_val <- predict(lasso_score_mod, scores_lasso_val, type = "response") %>% as.vector

# Get Baik predicted probabilities
scores_baik_val <- data.frame(baik_scores = X_val %*% coef_baik$coef)
baik_pred_der <- predict(baik_score_mod, type = "response") %>% as.vector
baik_pred_val <- predict(baik_score_mod, scores_baik_val, type = "response") %>% as.vector

# Get NLLCD predicted probabilities
nllcd_pred_der <- predict(mod, type = "response")[,1]
nllcd_pred_val <- predict(mod, X_val, type = "response")[,1]

# Format AUC text
get_auc_text <- function(ci_auc_obj) {
  return(paste0(round(ci_auc_obj[[2]],3), " (", 
                round(ci_auc_obj[[1]],3), ", ", 
                round(ci_auc_obj[[3]],3), ")"))
}


# Calculate AUC
auc_lasso_der <- roc(y_der, lasso_pred_der, quiet = TRUE) %>% ci.auc() %>% get_auc_text()
auc_lasso_val <- roc(y_val, lasso_pred_val, quiet = TRUE) %>% ci.auc() %>% get_auc_text()

auc_rlasso_der <- roc(y_der, rlasso_pred_der, quiet = TRUE) %>% ci.auc() %>% get_auc_text()
auc_rlasso_val <- roc(y_val, rlasso_pred_val, quiet = TRUE) %>% ci.auc() %>% get_auc_text()

auc_baik_der <- roc(y_der, baik_pred_der, quiet = TRUE) %>% ci.auc() %>% get_auc_text()
auc_baik_val <- roc(y_val, baik_pred_val, quiet = TRUE) %>% ci.auc() %>% get_auc_text()

auc_nllcd_der <- roc(y_der, nllcd_pred_der, quiet = TRUE) %>% ci.auc() %>% get_auc_text()
auc_nllcd_val <- roc(y_val, nllcd_pred_val, quiet = TRUE) %>% ci.auc() %>% get_auc_text()



data.frame(Model = c("Lasso", "Rounded Lasso", "Baik 2020", "NLLCD"),
           AUC_der = c(auc_lasso_der, auc_rlasso_der, auc_baik_der, auc_nllcd_der),
           AUC_val = c(auc_lasso_val, auc_rlasso_val, auc_baik_val, auc_nllcd_val))


```



```{r}
# Mean absolute difference in estimated risk 

# NLLCD
nllcd_calibration <- data.frame(score = predict(mod, X_val, type = "score"),
           outcome = y_val) %>%
  group_by(score) %>%
  summarize(obs_risk = mean(outcome)) %>%
  mutate(est_risk = get_risk(mod, score))

baik_calibration <- data.frame(score = scores_baik_val$baik_scores,
           outcome = y_val,
           est_risk = predict(baik_score_mod, scores_baik_val, type = "response")) %>%
  group_by(score, est_risk) %>%
  summarize(obs_risk = mean(outcome))



ggplot() + 
geom_line(aes(x = est_risk, y = obs_risk), data = nllcd_calibration, color = "green") +
geom_line(aes(x = est_risk, y = obs_risk), data = baik_calibration, color = "red") + 
geom_abline(xintercept = 0, yintercept = 0, slope = 1)


```

```{r}
# Observed vs predicted probabilities in validation population

data.frame(score = predict(mod, X_val, type = "score")[,1],
           est_risk = predict(mod, X_val, type = "response")[,1],
           outcome = y_val
) %>%
  group_by(score, est_risk) %>%
  summarize(obs_risk = mean(outcome), n = n())

```


```{r}
# Calibration plots

cal_der <- data.frame(y_der, X_der[,-1], baik_der = baik_pred_der, 
                      riskcd_der = nllcd_pred_der)

cal_val <- data.frame(y_val, X_val[,-1], baik_val = baik_pred_val, 
                      riskcd_val = nllcd_pred_val)

cal_der_baik <- cal_der %>%
  cal_plot_logistic(y_der, baik_der) + 
  labs(x = "Observed Risk", y = "Estimated Risk", title = "Derivation Data, Baik2020")

cal_der_riskcd <- cal_der %>%
  cal_plot_logistic(y_der, riskcd_der) + 
  labs(x = "Observed Risk", y = "Estimated Risk", title = "Derivation Data, RiskCD-CV")

cal_val_baik <- cal_val %>%
  cal_plot_logistic(y_val, baik_val, smooth = FALSE) + 
  labs(x = "Observed Risk", y = "Estimated Risk", title = "Validation Data, Baik2020")

cal_val_riskcd <- cal_val %>%
  cal_plot_logistic(y_val, riskcd_val) + 
  labs(x = "Observed Risk", y = "Estimated Risk", title = "Validation Data, RiskCD-CV")

cal_arrange <- grid.arrange(cal_der_baik, cal_der_riskcd, cal_val_baik, cal_val_riskcd, ncol = 2)
ggsave(cal_arrange, width = 7, height = 7, dpi = 300, filename = "diagnosis-calibration.png")
```

```{r}
# Brier score

# Validation set
mean((lasso_pred_val - y_val)^2)
mean((rlasso_pred_val - y_val)^2)
mean((baik_pred_val - y_val)^2)
mean((nllcd_pred_val - y_val)^2)


```


\pagebreak

# Code Appendix



```{r  ref.label=knitr::all_labels(), echo=TRUE, eval=FALSE, include=TRUE}

```


